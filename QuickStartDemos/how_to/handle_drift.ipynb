{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9640d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e91f5",
   "metadata": {},
   "source": [
    "# Handle motion/drift with spikeinterface\n",
    "\n",
    "Spikeinterface offers a very flexible framework to handle drift as a preprocessing step.\n",
    "If you want to know more, please read the `motion_correction` section of the documentation.\n",
    "\n",
    "Here is a short demo on how to handle drift using the high-level function `spikeinterface.preprocessing.compute_motion()`.\n",
    "\n",
    "This function takes a preprocessed recording as input and returns a `motion` object, which contains the\n",
    "information required to interpolate your recording. You can additionally return a `motion_info` object\n",
    "which contains the peaks, peak_locations and parameters used to compute the `motion` object by passing\n",
    "`output_motion_info = True` to the `compute_motion` function. Note that you can alternatively compute\n",
    "the motion correction and interpolate at the same time using the `spikeinterface.preprocessing.correct_motion()`\n",
    "function.\n",
    "\n",
    "Internally the function `compute_motion` runs the following steps (which can be slow!):\n",
    "\n",
    "     1. detect_peaks()\n",
    "     2. localize_peaks()\n",
    "     3. select_peaks() (optional)\n",
    "     4. estimate_motion()\n",
    "\n",
    "All these sub-steps can be run with different methods and have many parameters.\n",
    "\n",
    "The high-level function suggests several predefined \"presets\" and we will explore them using a very well known public dataset recorded by Nick Steinmetz:\n",
    "[Imposed motion datasets](https://figshare.com/articles/dataset/_Imposed_motion_datasets_from_Steinmetz_et_al_Science_2021/14024495)\n",
    "\n",
    "This dataset contains 3 recordings and each recording contains a Neuropixels 1 and a Neuropixels 2 probe.\n",
    "\n",
    "Here we will use *dataset1* with *neuropixel1*. This dataset is the *\"hello world\"* for drift correction in the spike sorting community!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "\n",
    "import spikeinterface.full as si\n",
    "\n",
    "from spikeinterface.preprocessing import get_motion_parameters_preset, get_motion_presets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path(\"/home/nolanlab/Work/Data\")\n",
    "dataset_folder = base_folder / \"dataset1/NP1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ec07d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# read the file\n",
    "raw_rec = si.read_spikeglx(dataset_folder)\n",
    "raw_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae22d3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We preprocess the recording with bandpass filter and a common median reference.\n",
    "Note, that it is better to not whiten the recording before motion estimation to get a better estimate of peak locations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_chain(rec):\n",
    "    rec = rec.astype('float32')\n",
    "    rec = si.bandpass_filter(rec, freq_min=300.0, freq_max=6000.0)\n",
    "    rec = si.common_reference(rec, reference=\"global\", operator=\"median\")\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = preprocess_chain(raw_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_kwargs = dict(n_jobs=40, chunk_duration=\"1s\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56005730",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Correcting for drift is easy! You just need to run a single function.\n",
    "We will try this function with some presets.\n",
    "\n",
    "Internally a preset is a dictionary of dictionaries containing all parameters for every steps.\n",
    "\n",
    "Here we also save the motion correction results into a folder to be able to load them later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62e2c1",
   "metadata": {},
   "source": [
    "### Preset and parameters\n",
    "\n",
    "Motion correction has some steps and every step can be controlled by a method and related parameters.\n",
    "\n",
    "A preset is a nested dict that contains theses methods/parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165eb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset_keys = get_motion_presets()\n",
    "preset_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_preset_params = get_motion_parameters_preset(\"kilosort_like\")\n",
    "one_preset_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d7eae",
   "metadata": {},
   "source": [
    "### Run motion correction with one function!\n",
    "\n",
    "Correcting for drift is easy! You just need to run a single function.\n",
    "We will try this function with some presets.\n",
    "\n",
    "Here we also save the motion correction results into a folder to be able to load them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b57511",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# lets try theses presets\n",
    "some_presets = (\"rigid_fast\", \"kilosort_like\",  \"nonrigid_accurate\", \"nonrigid_fast_and_accurate\", \"dredge\", \"dredge_fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1edf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute motion with theses presets\n",
    "for preset in some_presets:\n",
    "    print(\"Computing with\", preset)\n",
    "    folder = base_folder / \"motion_folder_dataset1\" / preset\n",
    "    if folder.exists():\n",
    "        shutil.rmtree(folder)\n",
    "    motion, motion_info = si.compute_motion(\n",
    "        rec, preset=preset, folder=folder, output_motion_info=True, **job_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e8f260",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "\n",
    "We load back the results and use the widgets module to explore the estimated drift motion.\n",
    "\n",
    "For all methods we have 4 plots:\n",
    "\n",
    "  * top left: time vs estimated peak depth\n",
    "  * top right: time vs peak depth after motion correction\n",
    "  * bottom left: the average motion vector across depths and all motion across spatial depths (for non-rigid estimation)\n",
    "  * bottom right: if motion correction is non rigid, the motion vector across depths is plotted as a map, with the color code representing the motion in micrometers.\n",
    "\n",
    "A few comments on the figures:\n",
    "  * the preset **'rigid_fast'** has only one motion vector for the entire probe because it is a \"rigid\" case.\n",
    "    The motion amplitude is globally underestimated because it averages across depths.\n",
    "    However, the corrected peaks are flatter than the non-corrected ones, so the job is partially done.\n",
    "    The big jump at=600s when the probe start moving is recovered quite well.\n",
    "  * The preset **kilosort_like** gives better results because it is a non-rigid case.\n",
    "    The motion vector is computed for different depths.\n",
    "    The corrected peak locations are flatter than the rigid case.\n",
    "    The motion vector map is still be a bit noisy at some depths (e.g around 1000um).\n",
    "  * The preset **dredge** is offcial DREDge re-implementation in spikeinterface.\n",
    "    It give the best result : very fast and smooth motion estimation. Very few noise.\n",
    "    This method also capture very well the non rigid motion gradient along the probe.\n",
    "    The best method on the market at the moement.\n",
    "    An enormous thanks to the dream team :  Charlie Windolf, Julien Boussard, Erdem Varol, Liam Paninski.\n",
    "    Note that in the first part of the recording before the imposed motion (0-600s) we clearly have a non-rigid motion:\n",
    "    the upper part of the probe (2000-3000um) experience some drifts, but the lower part (0-1000um) is relatively stable.\n",
    "    The method defined by this preset is able to capture this.\n",
    "  * The preset **nonrigid_accurate** this is the ancestor of \"dredge\" before it was published.\n",
    "    It seems to give the good results on this recording but with bit more noise.\n",
    "  * The preset **dredge_fast** similar than dredge but faster (using grid_convolution).\n",
    "  * The preset **nonrigid_fast_and_accurate** a variant of nonrigid_accurate but faster (using grid_convolution).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7dbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for preset in some_presets:\n",
    "    # load\n",
    "    folder = base_folder / \"motion_folder_dataset1\" / preset\n",
    "    motion_info = si.load_motion_info(folder)\n",
    "\n",
    "    # and plot\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    si.plot_motion_info(\n",
    "        motion_info, rec,\n",
    "        figure=fig,\n",
    "        depth_lim=(400, 600),\n",
    "        color_amplitude=True,\n",
    "        amplitude_cmap=\"inferno\",\n",
    "        scatter_decimate=10,\n",
    "    )\n",
    "\n",
    "    fig.suptitle(f\"{preset=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb53fb",
   "metadata": {},
   "source": [
    "### Make an interpolated recording\n",
    "\n",
    "Once you have analyzed your results you can choose the motion correction method that works best on your dataset, and\n",
    "create an interpolated recording using `interpolate_motion`. The motion object itself is contained in the `motion_info` dict.\n",
    "Suppose we decide to use the `nonrigid_accurate` preset to make the interpolated recording. We do this as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06217f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.sortingcomponents.motion import interpolate_motion\n",
    "preset = \"nonrigid_accurate\"\n",
    "folder = base_folder / \"motion_folder_dataset1\" / preset\n",
    "motion_info = si.load_motion_info(folder)\n",
    "motion = motion_info['motion']\n",
    "interpolated_recording = interpolate_motion(recording=rec, motion=motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e371c226",
   "metadata": {},
   "source": [
    "You can then use the interpolated recording for e.g. spike sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4644c9",
   "metadata": {},
   "source": [
    "### Plot peak localization\n",
    "\n",
    "We can also use the internal extra results (peaks and peaks location) to check if putative clusters have a lower spatial spread after the motion correction.\n",
    "\n",
    "Here we plot the estimated peak locations (left) and the corrected peak locations (on right) on top of the probe.\n",
    "The color codes for the peak amplitudes.\n",
    "\n",
    "We can see here that some clusters seem to be more compact on the 'y' axis, especially for the preset \"nonrigid_accurate\".\n",
    "\n",
    "Be aware that there are two ways to correct for the motion:\n",
    "\n",
    "  1. Interpolate traces and detect/localize peaks again  (`interpolate_recording()`)\n",
    "  2. Compensate for drifts directly on peak locations (`correct_motion_on_peaks()`)\n",
    "\n",
    "Case 1 is used before running a spike sorter and the case 2 is used here to display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.sortingcomponents.motion import correct_motion_on_peaks\n",
    "\n",
    "for preset in some_presets:\n",
    "    folder = base_folder / \"motion_folder_dataset1\" / preset\n",
    "    motion_info = si.load_motion_info(folder)\n",
    "\n",
    "    motion = motion_info[\"motion\"]\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(12, 8), sharey=True)\n",
    "\n",
    "    ax = axs[0]\n",
    "    si.plot_probe_map(rec, ax=ax)\n",
    "\n",
    "    peaks = motion_info[\"peaks\"]\n",
    "    sr = rec.get_sampling_frequency()\n",
    "    time_lim0 = 750.0\n",
    "    time_lim1 = 1500.0\n",
    "    mask = (peaks[\"sample_index\"] > int(sr * time_lim0)) & (peaks[\"sample_index\"] < int(sr * time_lim1))\n",
    "    sl = slice(None, None, 5)\n",
    "    amps = np.abs(peaks[\"amplitude\"][mask][sl])\n",
    "    amps /= np.quantile(amps, 0.95)\n",
    "    c = plt.get_cmap(\"inferno\")(amps)\n",
    "\n",
    "    color_kargs = dict(alpha=0.2, s=2, c=c)\n",
    "\n",
    "    peak_locations = motion_info[\"peak_locations\"]\n",
    "    # color='black',\n",
    "    ax.scatter(peak_locations[\"x\"][mask][sl], peak_locations[\"y\"][mask][sl], **color_kargs)\n",
    "\n",
    "    peak_locations2 = correct_motion_on_peaks(peaks, peak_locations, motion,rec)\n",
    "\n",
    "    ax = axs[1]\n",
    "    si.plot_probe_map(rec, ax=ax)\n",
    "    #  color='black',\n",
    "    ax.scatter(peak_locations2[\"x\"][mask][sl], peak_locations2[\"y\"][mask][sl], **color_kargs)\n",
    "\n",
    "    ax.set_ylim(400, 600)\n",
    "    fig.suptitle(f\"{preset=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50498c94",
   "metadata": {},
   "source": [
    "## run times\n",
    "\n",
    "Presets and related methods have different accuracies but also computation speeds.\n",
    "It is good to have this in mind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f345a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_times = []\n",
    "for preset in some_presets:\n",
    "    folder = base_folder / \"motion_folder_dataset1\" / preset\n",
    "    motion_info = si.load_motion_info(folder)\n",
    "    run_times.append(motion_info[\"run_times\"])\n",
    "keys = run_times[0].keys()\n",
    "\n",
    "bottom = np.zeros(len(run_times))\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "for k in keys:\n",
    "    rtimes = np.array([rt[k] for rt in run_times])\n",
    "    if np.any(rtimes > 0.0):\n",
    "        ax.bar(some_presets, rtimes, bottom=bottom, label=k)\n",
    "    bottom += rtimes\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:light,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
