{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e27c0c",
   "metadata": {},
   "source": [
    "# Estimate drift using the LFP traces\n",
    "\n",
    "Drift is a well known issue for long shank probes. Some datasets, especially from primates and humans, can experience very fast motion due to breathing and heart beats. In these cases, the standard motion estimation methods that use detected spikes as a basis for motion inference will fail, because there are not enough spikes to \"follow\" such fast drifts.\n",
    "\n",
    "Charlie Windolf and colleagues from the Paninski Lab at Columbia have developed a method to estimate the motion using the LFP signal: **DREDge**. (more details about the method in the paper [DREDge: robust motion correction for high-density extracellular recordings across species](https://doi.org/10.1101/2023.10.24.563768)).\n",
    "\n",
    "This method is particularly suited for the open dataset recorded at Massachusetts General Hospital by Angelique Paulk and colleagues in humans (more details in the [paper](https://doi.org/10.1038/s41593-021-00997-0)). The dataset can be dowloaed from [datadryad](https://datadryad.org/stash/dataset/doi:10.5061/dryad.d2547d840) and it contains recordings on human patients with a Neuropixels probe, some of which with very high and fast motion on the probe, which prevents accurate spike sorting without a proper and adequate motion correction\n",
    "\n",
    "The **DREDge** method has two options: **dredge_lfp** and **dredge_ap**, which have both been ported inside `SpikeInterface`.\n",
    "\n",
    "Here we will demonstrate the **dredge_lfp** method to estimate the fast and high drift on this recording.\n",
    "\n",
    "For each patient, the dataset contains two streams:\n",
    "\n",
    "* a highpass \"action potential\" (AP), sampled at 30kHz\n",
    "* a lowpass \"local field\" (LF) sampled at 2.5kHz\n",
    "\n",
    "For this demonstration, we will use the LF stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9070115",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72694b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spikeinterface.full as si\n",
    "from spikeinterface.sortingcomponents.motion import estimate_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fcfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset has been downloaded locally\n",
    "base_folder = Path(\"/mnt/data/sam/DataSpikeSorting/\")\n",
    "np_data_drift = base_folder / \"human_neuropixel\" / \"Pt02\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd818b",
   "metadata": {},
   "source": [
    "### Read the spikeglx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a865023",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_rec = si.read_spikeglx(np_data_drift)\n",
    "print(raw_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b952a",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Contrary to the **dredge_ap** approach, which needs detected peaks and peak locations, the **dredge_lfp** method is estimating the motion directly on traces.\n",
    "Importantly, the method requires some additional pre-processing steps:\n",
    "  * `bandpass_filter`: to \"focus\" the signal on a particular band\n",
    "  * `phase_shift`: to compensate for the sampling misalignement\n",
    "  * `resample`: to further reduce the sampling fequency of the signal and speed up the computation. The sampling frequency of the estimated motion will be the same as the resampling frequency. Here we choose 250Hz, which corresponds to a sampling interval of 4ms.\n",
    "  * `directional_derivative`: this optional step applies a second order derivative in the spatial dimension to enhance edges on the traces.\n",
    "    This is not a general rules and need to be tested case by case.\n",
    "  * `average_across_direction`: Neuropixels 1.0 probes have two contacts per depth. This steps averages them to obtain a unique virtual signal along the probe depth (\"y\" in `spikeinterface`).\n",
    "\n",
    "After appying this preprocessing chain, the motion can be estimated almost by eyes ont the traces plotted with the map mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c089f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfprec = si.bandpass_filter(\n",
    "    raw_rec,\n",
    "    freq_min=0.5,\n",
    "    freq_max=250,\n",
    "    margin_ms=1500.,\n",
    "    filter_order=3,\n",
    "    dtype=\"float32\",\n",
    "    add_reflect_padding=True,\n",
    ")\n",
    "lfprec = si.phase_shift(lfprec)\n",
    "lfprec = si.resample(lfprec, resample_rate=250, margin_ms=1000)\n",
    "\n",
    "lfprec = si.directional_derivative(lfprec, order=2, edge_order=1)\n",
    "lfprec = si.average_across_direction(lfprec)\n",
    "\n",
    "print(lfprec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41afc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "si.plot_traces(lfprec, backend=\"matplotlib\", mode=\"map\", clim=(-0.05, 0.05), time_range=(400, 420))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd757cab",
   "metadata": {},
   "source": [
    "### Run the method\n",
    "\n",
    "`estimate_motion()` is the generic function to estimate motion with multiple methods in `spikeinterface`.\n",
    "\n",
    "This function returns a `Motion` object and we can notice that the interval is exactly the same as downsampled signal.\n",
    "\n",
    "Here we use `rigid=True`, which means that we have one unqiue signal to describe the motion across the entire probe depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15520c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = estimate_motion(lfprec, method='dredge_lfp', rigid=True, progress_bar=True)\n",
    "motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74597a73",
   "metadata": {},
   "source": [
    "### Plot the drift\n",
    "\n",
    "When plotting the drift, we can notice a very fast drift which corresponds to the heart rate. The slower oscillations can be attributed to the breathing signal.\n",
    "\n",
    "We can appreciate how the estimated motion signal matches the processed LFP traces plotted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "si.plot_motion(motion, mode='line', ax=ax)\n",
    "ax.set_xlim(400, 420)\n",
    "ax.set_ylim(800, 1300)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
