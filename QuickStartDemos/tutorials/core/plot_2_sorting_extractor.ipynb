{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sorting objects\n\nThe :py:class:`~spikeinterface.core.BaseSorting` is the basic class for handling spike sorted data.\nHere is how it works.\n\nA SortingExtractor handles:\n\n  * spike trains retrieval across segments\n  * dumping to/loading from dict-json\n  * saving (caching)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport spikeinterface.extractors as se"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create a :code:`SortingExtractor` object from scratch using :code:`numpy` and the\n:py:class:`~spikeinterface.core.NumpySorting`\n\nLet's define the properties of the dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampling_frequency = 30000.0\nduration = 20.0\nnum_timepoints = int(sampling_frequency * duration)\nnum_units = 4\nnum_spikes = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We generate some random events for 2 segments:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "times0 = np.int_(np.sort(np.random.uniform(0, num_timepoints, num_spikes)))\nlabels0 = np.random.randint(1, num_units + 1, size=num_spikes)\n\ntimes1 = np.int_(np.sort(np.random.uniform(0, num_timepoints, num_spikes)))\nlabels1 = np.random.randint(1, num_units + 1, size=num_spikes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And instantiate a :py:class:`~spikeinterface.core.NumpySorting` object:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sorting = se.NumpySorting.from_samples_and_labels([times0, times1], [labels0, labels1], sampling_frequency)\nprint(sorting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now print properties that the :code:`SortingExtractor` retrieves from\nthe underlying sorted dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Unit ids = {}\".format(sorting.get_unit_ids()))\nst = sorting.get_unit_spike_train(unit_id=1, segment_index=0)\nprint(\"Num. events for unit 1seg0 = {}\".format(len(st)))\nst1 = sorting.get_unit_spike_train(unit_id=1, start_frame=0, end_frame=30000, segment_index=1)\nprint(\"Num. events for first second of unit 1 seg1 = {}\".format(len(st1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some extractors also implement a :code:`write` function. We can for example\nsave our newly created sorting object to NPZ format (a simple format based\non numpy used in :code:`spikeinterface`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "file_path = \"my_sorting.npz\"\nse.NpzSortingExtractor.write_sorting(sorting, file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now read it back with the proper extractor:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sorting2 = se.NpzSortingExtractor(file_path)\nprint(sorting2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unit properties are key value pairs that we can store for any unit.\nWe will now calculate unit firing rates and add them as properties to\nthe :code:`SortingExtractor` object:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "firing_rates = []\nfor unit_id in sorting2.get_unit_ids():\n    st = sorting2.get_unit_spike_train(unit_id=unit_id, segment_index=0)\n    firing_rates.append(st.size / duration)\nsorting2.set_property(\"firing_rate\", firing_rates)\n\nprint(sorting2.get_property(\"firing_rate\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also get a a sorting with a subset of unit. Properties are\npropagated to the new object:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sorting3 = sorting2.select_units(unit_ids=[1, 4])\nprint(sorting3)\n\nprint(sorting3.get_property(\"firing_rate\"))\n\n# which is equivalent to\nfrom spikeinterface import UnitsSelectionSorting\n\nsorting3 = UnitsSelectionSorting(sorting2, unit_ids=[1, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A sorting can be \"dumped\" (exported) to:\n * a dict\n * a json file\n * a pickle file\n\nThe \"dump\" operation is lazy, i.e., the spike trains are not exported.\nOnly the information about how to reconstruct the sorting are dumped:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from spikeinterface import load_extractor\nfrom pprint import pprint\n\nd = sorting2.to_dict()\npprint(d)\n\nsorting2_loaded = load_extractor(d)\nprint(sorting2_loaded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dictionary can also be dumped directly to a JSON file on disk:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sorting2.dump(\"my_sorting.json\")\n\nsorting2_loaded = load_extractor(\"my_sorting.json\")\nprint(sorting2_loaded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**IMPORTANT**: the \"dump\" operation DOES NOT copy the spike trains to disk!\n\nIf you wish to also store the spike trains in a compact way you need to use the\n:code:`save()` function:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sorting2.save(folder=\"./my_sorting\")\n\nimport os\n\npprint(os.listdir(\"./my_sorting\"))\n\nsorting2_cached = load_extractor(\"./my_sorting\")\nprint(sorting2_cached)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}